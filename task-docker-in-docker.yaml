apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: execute-in-dind-task
spec:
  inputs:
    params:
      - name: task-pvc
        description: the output pvc - this is the name of the PVC that is mounted for the execution of the task
      # Dockerfile location
      - name: imageUrl
        description: Image url
        default: ""
      - name: clusterName
        description: Cluster name
        default: ""
      - name: instanceName
        description: Name of the instance
        default: "" 
      - name: featuresUrl
        description: Features URL
        default: ""                       
      - name: analyticsapikey
        description: API key
        default: ""        
      - name: appName
        description: appName
        default: ""
      - name: instanceId
        description: instanceId
        default: ""        
      - name: resourceGroup
        description: Resource group
        default: ""
      - name: continuous-delivery-context-secret
        description: name of the configmap containing the continuous delivery pipeline context secrets
        default: cd-secret        
  steps:
    - name: git-clone
      image: ibmcom/pipeline-base-image
      env:
        - name: GIT_TOKEN
          valueFrom:
            secretKeyRef:
              name: $(inputs.params.continuous-delivery-context-secret)
              key: GIT_TOKEN                                 
      command: ["/bin/bash", "-c"]
      args:
        - |
          set -e -o pipefail
          git clone -b master https://$GIT_TOKEN@github.ibm.com/devx-app-services/devx-appfoundation-samples
          ls -la 
      volumeMounts:
        - mountPath: /artifacts
          name: task-volume
        - mountPath: /steps
          name: steps-volume
        - mountPath: /certs/client
          name: dind-certs
    - name: feature-flag-retrieval
      image: ibmcom/pipeline-base-image
      env:
        - name: instanceName
          value: $(inputs.params.instanceName)      
        - name: featuresUrl
          value: $(inputs.params.featuresUrl)      
        - name: appName
          value: $(inputs.params.appName)      
        - name: instanceId
          value: $(inputs.params.instanceId)
        - name: analyticsapikey
          value: $(inputs.params.analyticsapikey)      
        - name: GIT_TOKEN
          valueFrom:
            secretKeyRef:
              name: $(inputs.params.continuous-delivery-context-secret)
              key: GIT_TOKEN                                 
      command: ["/bin/bash", "-c"]
      args:
        - |
          set -e -o pipefail
          cd devx-appfoundation-samples/WebSamples/devx-appfoundation-ghzrentalapp
          ls -la
          
          if [ ! -f ./config/production.json ]; then
             touch ./config/production.json
          fi
          echo "features url is $featuresUrl"
          jsonVal=$(curl $featuresUrl | jq -r)
          jq -r '.[] | { (.name): .enabled }' <<<"$jsonVal" | jq -s 'add' > ./config/production.json
          echo "instance name is $instanceName"
          echo "Got Flags. Written to the config - " 
          cat ./config/production.json
          jq --arg instanceId "${instanceId}" '.instanceId=$instanceId' ./config/production.json >  "tmp" && mv "tmp" ./config/production.json
          jq --arg appName "${appName}" '.appName=$appName' ./config/production.json >  "tmp" && mv "tmp" ./config/production.json          
          jq --arg name "${instanceName}" '.instanceName=$name' ./config/production.json >  "tmp" && mv "tmp" ./config/production.json
          jq --arg apikey "${analyticsapikey}" '.analyticsapikey=$apikey' ./config/production.json >  "tmp" && mv "tmp" ./config/production.json
          jq --arg featuresUrl "${featuresUrl}" '.featuresUrl=$featuresUrl' ./config/production.json >  "tmp" && mv "tmp" ./config/production.json
      volumeMounts:
        - mountPath: /artifacts
          name: task-volume
        - mountPath: /steps
          name: steps-volume
        - mountPath: /certs/client
          name: dind-certs
    - name: docker-build
      image: ibmcom/pipeline-base-image
      env:
        - name: imageUrl
          value: $(inputs.params.imageUrl)      
        - name: resourceGroup
          value: $(inputs.params.resourceGroup)
        - name: BUILD_NUMBER
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['devops.cloud.ibm.com/build-number']   
        - name: API_KEY
          valueFrom:
            secretKeyRef:
              name: $(inputs.params.continuous-delivery-context-secret)
              key: API_KEY  
        - name: GIT_TOKEN
          valueFrom:
            secretKeyRef:
              name: $(inputs.params.continuous-delivery-context-secret)
              key: GIT_TOKEN                                 
      command: ["/bin/bash", "-c"]
      args:
        - |
          set -e -o pipefail
          ##########################################################################
          # Setting HOME explicitly to have ibmcloud plugins available
          # doing the export rather than env definition is a workaround
          # until https://github.com/tektoncd/pipeline/issues/1836 is fixed
          export HOME="/root"
          ##########################################################################
                    
          cd devx-appfoundation-samples/WebSamples/devx-appfoundation-ghzrentalapp
          ls -la
          BUILT_IMAGE="$imageUrl:$BUILD_NUMBER"
          echo "built image $BUILT_IMAGE"
          
          echo "Beginning of config json display"
          cat ./config/production.json
          echo "End of config json display"
          
          ibmcloud config --check-version false
          ibmcloud login -a https://cloud.ibm.com -r us-south --apikey $API_KEY    
          ibmcloud target -g $resourceGroup      
          ibmcloud cr build -t $BUILT_IMAGE .
          #BUILT_IMAGE="$REGISTRY_URL/$REGISTRY_NAMESPACE/$IMAGE_NAME:$BUILD_NUMBER"
          echo "image is $BUILT_IMAGE"
          echo "Docker Image has been pushed to us.icr.io"
      volumeMounts:
        - mountPath: /artifacts
          name: task-volume
        - mountPath: /steps
          name: steps-volume
        - mountPath: /certs/client
          name: dind-certs
    - name: deploy
      image: ibmcom/pipeline-base-image
      env:
        - name: imageUrl
          value: $(inputs.params.imageUrl)      
        - name: clusterName
          value: $(inputs.params.clusterName)
        - name: resourceGroup
          value: $(inputs.params.resourceGroup)
        - name: BUILD_NUMBER
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['devops.cloud.ibm.com/build-number']   
        - name: API_KEY
          valueFrom:
            secretKeyRef:
              name: $(inputs.params.continuous-delivery-context-secret)
              key: API_KEY  
      command: ["/bin/bash", "-c"]
      args:
        - |
          set -e -o pipefail
          ##########################################################################
          # Setting HOME explicitly to have ibmcloud plugins available
          # doing the export rather than env definition is a workaround
          # until https://github.com/tektoncd/pipeline/issues/1836 is fixed
          export HOME="/root"
          ##########################################################################
          echo "cluster name from param is $clusterName"
          cd devx-appfoundation-samples/WebSamples/devx-appfoundation-ghzrentalapp
          ls -la
          BUILT_IMAGE="$imageUrl:$BUILD_NUMBER"
          REGISTRY_REGION="us-south"
          ibmcloud config --check-version false
          ibmcloud login -a https://cloud.ibm.com -r $REGISTRY_REGION --apikey $API_KEY
          ibmcloud target -g $resourceGroup
          # Log container registry to the appropriate region
          ibmcloud cr region-set $REGISTRY_REGION
          ibmcloud cr info
          
          $(ibmcloud ks cluster config --cluster $clusterName --export);
          IP_ADDR=$( ibmcloud cs workers $clusterName | grep normal | awk '{ print $2 }' )
          
          DEPLOYMENT_FILE="config/kube/deployment.yaml"
          echo "deployment file $DEPLOYMENT_FILE"
          sed -i 's=$IMAGE='"$BUILT_IMAGE"'=g' $DEPLOYMENT_FILE
          
          
          echo "cat $DEPLOYMENT_FILE"
          cat $DEPLOYMENT_FILE
          echo "-----------------"
          echo "kubectl apply -f $DEPLOYMENT_FILE"
          kubectl apply -f $DEPLOYMENT_FILE
          echo ""
          SERVICE_NAME="appservice-cdintegration"
          kubectl apply -f config/kube/service.yaml
          echo ""
          echo "DEPLOYED SERVICE:"
          kubectl describe services $SERVICE_NAME -n appservice
          echo ""
          echo "DEPLOYED PODS:"
          kubectl describe pods -n appservice --selector app=$SERVICE_NAME 
          echo ""

          # Make sure the cluster is running and get the ip_address
          ip_addr=$(ibmcloud cs workers $clusterName | grep normal | awk '{ print $2 }')
          echo "--------- $ip_addr"
          if [ -z $ip_addr ]; then
            echo "$clusterName not created or workers not ready"
            exit 1
          fi

          # Show the IP address and the PORT of the running app
          port=$(kubectl get services -n appservice | grep "$SERVICE_NAME" | sed 's/.*:\([0-9]*\).*/\1/g')
          echo "RUNNING APPLICATION:"
          echo "URL=http://$ip_addr"
          echo "PORT=$port"
          echo ""
          echo "$SERVICE_NAME running at: http://$ip_addr:$port"
          
      volumeMounts:
        - mountPath: /artifacts
          name: task-volume
        - mountPath: /steps
          name: steps-volume
        - mountPath: /certs/client
          name: dind-certs          
  volumes:
    - name: task-volume
      persistentVolumeClaim:
        claimName: $(inputs.params.task-pvc)
    - name: steps-volume
      emptyDir: {}
    - name: dind-certs
      emptyDir: {}
  sidecars:
    - image: docker:dind
      name: server
      securityContext:
        privileged: true
      env:
        # Write generated certs to the path shared with the client.
        - name: DOCKER_TLS_CERTDIR
          value: /certs
      volumeMounts:
        - mountPath: /certs/client
          name: dind-certs
      # Wait for the dind daemon to generate the certs it will share with the client.
      readinessProbe:
        periodSeconds: 1
        exec:
          command: ["ls", "/certs/client/ca.pem"]